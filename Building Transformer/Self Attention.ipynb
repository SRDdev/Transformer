{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2294b39",
   "metadata": {},
   "source": [
    "# Self Attention\n",
    "\n",
    "Self-attention is a mechanism used in neural networks for processing sequential data, such as natural language text. It allows the network to weigh the importance of different input tokens while processing each token, based on their relationships with other tokens in the sequence. This can improve the network's ability to capture long-range dependencies and improve performance on tasks such as language modeling, machine translation, and summarization\n",
    "\n",
    "#### The self attention logic consists of 3 main components\n",
    "\n",
    "Query vector : What I am looking for ? [$sequence_{length}$ x $d_k$]\n",
    "\n",
    "Key vector : What I can offer ? [$sequence_{length}$ x $d_k$]\n",
    "\n",
    "Value vector : What I actually offer ? [$sequence_{length}$ x $d_v$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3849da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd457e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 4            #sequence length\n",
    "d_k = 8          #Key vector depth\n",
    "d_v = 8          #Value vector depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bb950",
   "metadata": {},
   "source": [
    "Now we will randomly initialize these vectors , but remember these are going to be your input vectors, this means they wont be random and each of them will have certain meaning of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77977f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[7.52693105e-01 8.41580563e-03 3.31019286e-04 8.97157650e-01\n",
      "  4.56170924e-02 5.70429534e-01 3.67254418e-01 5.02569250e-01]\n",
      " [7.23369714e-01 6.19765185e-01 3.98904336e-01 8.61107423e-01\n",
      "  1.46284758e-01 3.90607989e-01 9.91994667e-01 5.65312292e-01]\n",
      " [6.39388865e-01 1.30754719e-01 6.21434922e-01 9.79058090e-01\n",
      "  7.48285994e-01 1.11900671e-01 9.96873555e-01 2.78966113e-01]\n",
      " [5.60582814e-01 5.22478141e-01 3.50465399e-01 6.33301196e-01\n",
      "  9.58188269e-01 3.44813768e-01 9.95591738e-01 6.79213608e-01]]\n",
      "K\n",
      " [[0.36940241 0.04758322 0.83227899 0.58179784 0.76644583 0.41606289\n",
      "  0.78130063 0.83697154]\n",
      " [0.31768957 0.63863752 0.71029805 0.74194598 0.12293787 0.39578146\n",
      "  0.60758719 0.66235779]\n",
      " [0.37980848 0.40041257 0.58743129 0.976559   0.02782404 0.55686997\n",
      "  0.43654198 0.30334982]\n",
      " [0.76736693 0.45626942 0.1207564  0.72951051 0.59864137 0.73650732\n",
      "  0.36305381 0.58976947]]\n",
      "V\n",
      " [[0.16361751 0.73154278 0.21663838 0.03725605 0.60247861 0.3641873\n",
      "  0.7826611  0.78808985]\n",
      " [0.8367454  0.54962405 0.82972723 0.16829955 0.5312548  0.31692946\n",
      "  0.36066661 0.970084  ]\n",
      " [0.56723548 0.28215378 0.7706862  0.81459851 0.01785379 0.89145555\n",
      "  0.4117529  0.13103037]\n",
      " [0.32207899 0.41790658 0.48395884 0.42849255 0.45288638 0.6980004\n",
      "  0.52085796 0.9508095 ]]\n"
     ]
    }
   ],
   "source": [
    "q = np.random.rand(L, d_k)\n",
    "k = np.random.rand(L, d_k)\n",
    "v = np.random.rand(L, d_v)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537133f2",
   "metadata": {},
   "source": [
    "##### The Self Attention Equation is given\n",
    "\n",
    "$$Self-Attention = softmax(\\frac{Q.K^T}{\\sqrt(d_k)}+M)V$$\n",
    "\n",
    "\n",
    "The `Q.K^T` operation can be thought of as a similarity measure between the query and key vectors. The dot product of two vectors measures the **cosine similarity** between them, which ranges from -1 (opposite directions) to 1 (same direction). \n",
    "\n",
    "The $\\sqrt d_k$ is included in the equation to reduce the variance of the cosine similarity calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc06ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09167661500062436, 0.05696953752983293, 0.16287550475168971)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the variance\n",
    "q.var() , k.var() , np.matmul(q,k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bc0cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09167661500062436, 0.05696953752983293, 0.020359438093961214)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the variance after normalization\n",
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431c9592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62952191, 0.60025173, 0.63543141, 0.74710233],\n",
       "       [0.93781036, 0.95374212, 0.85711157, 0.9132412 ],\n",
       "       [1.04710411, 0.84187715, 0.78463941, 0.84725383],\n",
       "       [1.10177229, 0.89789669, 0.74450752, 0.97668635]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understaning the scaled dot product \n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8202f9",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "This is generally required in the decoder part of the Transformer Architecture. This is to ensure words dont get context from words generated in the future. Not used in encoders.\n",
    "\n",
    "The generated mask is a upper trangular mask. Continuing the last example if the 1st row is a vector for My , \n",
    "them My is only allowed to look at My and no other word.\n",
    "Similarly as you will notice , Name which is represented by the second row is only alloed to view My & Name \n",
    "for predicting the next word in the sequence.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225782c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones( (L, L) ))\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ceac22",
   "metadata": {},
   "source": [
    "Now a slight update to the original mask is to replace the 0 → - $\\infin$  and 1→ 0. This is then applied to the scaled calculations we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211b6d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62952191,       -inf,       -inf,       -inf],\n",
       "       [0.93781036, 0.95374212,       -inf,       -inf],\n",
       "       [1.04710411, 0.84187715, 0.78463941,       -inf],\n",
       "       [1.10177229, 0.89789669, 0.74450752, 0.97668635]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "scaled+mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b87e6f",
   "metadata": {},
   "source": [
    "### SoftMax\n",
    "\n",
    "It is used to convert a output vector into a probability distribution. This allows the sum of all the values in the output to sum up to 1. Allowing no value in the output to go beyond the probability of 100%.\n",
    "\n",
    "$$softmax = \\frac{e^{x_i}}{\\sum_je^x_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9406830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.49601715, 0.50398285, 0.        , 0.        ],\n",
       "       [0.38705443, 0.3152413 , 0.29770428, 0.        ],\n",
       "       [0.29432782, 0.24004312, 0.20590799, 0.25972107]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x) , axis=1)).T\n",
    "\n",
    "attention = softmax(scaled+mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401ada2",
   "metadata": {},
   "source": [
    "Now by multiplying the attention matrix with the Value matrix, we generate a new matrix which tells the model which vectors are important to predict which output vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03823731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16361751, 0.73154278, 0.21663838, 0.03725605, 0.60247861,\n",
       "        0.3641873 , 0.7826611 , 0.78808985],\n",
       "       [0.50286243, 0.63985886, 0.52562465, 0.10329973, 0.56658303,\n",
       "        0.34037016, 0.56998312, 0.87981178],\n",
       "       [0.49597402, 0.54040945, 0.57485171, 0.30998455, 0.40598061,\n",
       "        0.50625969, 0.53921006, 0.6498525 ],\n",
       "       [0.44946118, 0.51388372, 0.54731777, 0.33038552, 0.42615065,\n",
       "        0.54811042, 0.53699548, 0.73874422]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4932e405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16361751, 0.73154278, 0.21663838, 0.03725605, 0.60247861,\n",
       "       0.3641873 , 0.7826611 , 0.78808985])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c05d7",
   "metadata": {},
   "source": [
    "This `new_v` is the probabilities output of which means each row's sum is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa55fb",
   "metadata": {},
   "source": [
    "# Self Attention by Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd85e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f7ab0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention_weights, sentence):\n",
    "    # Plot the attention weights\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cax = ax.matshow(attention_weights, cmap='viridis')\n",
    "\n",
    "#     # Set up axes\n",
    "    ax.set_xticklabels([''] + sentence, rotation=90)\n",
    "    ax.set_yticklabels([''] + sentence)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.colorbar(cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8232f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00781989  0.61610943 -0.11527669 -0.4038552 ]\n",
      " [ 0.49752266  0.24294984 -1.17561012  0.78825445]\n",
      " [ 0.04239852  0.73203998  0.88182052  1.12598537]\n",
      " [-0.01200612  1.42462384  0.25916121 -0.10589021]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"My\",\"Name\",\"is\",\"Shreyas\"]\n",
    "num_words = len(sentence)\n",
    "attention_weights = np.random.randn(num_words,num_words)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc3d5c",
   "metadata": {},
   "source": [
    "The given sentence now needs to be converted into a vector using anyone of the Encoding techniques. We will not dive into that in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4cab904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9824\\3028894915.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, rotation=90)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9824\\3028894915.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + sentence)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(attention_weights, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4394ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
